{
    "machine": {
        "gpu": 1,
        "cpu": 1000,
        "ram": 8000
    },
    "job": {
        "APIVersion": "V1beta1",
        "Spec": {
            "Deal": {
                "Concurrency": 1
            },
            "Docker": {
                "Entrypoint": ["python", "run_llama.py"],
                "EnvironmentVariables": [
                    {{ if .prompt }}"PROMPT={{ .prompt }}"{{ else }}"PROMPT=test"{{ end }}
                ],
                "Image": "noryev/llama2-7b:latest"
            },
            "Engine": "Docker",
            "Network": {
                "Type": "None"
            },
            "Outputs": [
                {
                    "Name": "outputs",
                    "Path": "/outputs"
                }
            ],
            "PublisherSpec": {
                "Type": "ipfs"
            },
            "Resources": {
                "GPU": "1"
            },
            "Timeout": 1800
        }
    }
}